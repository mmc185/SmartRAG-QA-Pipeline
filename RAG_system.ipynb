{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --quiet langchain langchain_community langchain_core langchain-google-genai pypdf chromadb\n",
        "!pip install -U --quiet langchain_chroma"
      ],
      "metadata": {
        "id": "7KXqzSWVrYQW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Professional RAG (Retrieval-Augmented Generation) System\n",
        "A document processing and question-answering system using Google's Gemini models.\n",
        "\n",
        "Dependencies:\n",
        "    pip install langchain langchain_community langchain_core langchain-google-genai\n",
        "    pip install langchain_chroma pypdf chromadb\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RAGConfig:\n",
        "    \"\"\"Configuration class for RAG system parameters.\"\"\"\n",
        "    file_path: str\n",
        "    api_key: str\n",
        "    model_name: str = \"gemini-2.5-flash-lite\"\n",
        "    embedding_model: str = \"models/embedding-001\"\n",
        "    chunk_size: int = 500\n",
        "    chunk_overlap: int = 150\n",
        "    temperature: float = 0.0\n",
        "    retrieval_k: int = 3\n",
        "    score_threshold: float = 0.3  # Increased from 0.01 to be more selective\n",
        "    metadata_extraction_delay: float = 2.0\n",
        "    persist_directory: str = \"./chroma_db\"\n",
        "    min_page_words: int = 20\n",
        "    adaptive_threshold: bool = True  # Enable adaptive thresholding\n",
        "    min_relevant_docs: int = 1  # Minimum number of relevant docs needed\n",
        "\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"Handles document loading and preprocessing.\"\"\"\n",
        "\n",
        "    def __init__(self, config: RAGConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def load_and_clean_documents(self) -> List[Document]:\n",
        "        \"\"\"Load PDF and filter out pages with insufficient content.\"\"\"\n",
        "        try:\n",
        "            if not Path(self.config.file_path).exists():\n",
        "                raise FileNotFoundError(f\"File not found: {self.config.file_path}\")\n",
        "\n",
        "            loader = PyPDFLoader(self.config.file_path)\n",
        "            pages = loader.load()\n",
        "\n",
        "            cleaned_pages = [\n",
        "                page for page in pages\n",
        "                if len(page.page_content.split()) > self.config.min_page_words\n",
        "            ]\n",
        "\n",
        "            logger.info(f\"Loaded {len(pages)} pages, kept {len(cleaned_pages)} after cleaning\")\n",
        "            return cleaned_pages\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading documents: {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "class MetadataExtractor:\n",
        "    \"\"\"Handles metadata extraction from documents.\"\"\"\n",
        "\n",
        "    def __init__(self, config: RAGConfig):\n",
        "        self.config = config\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=config.model_name,\n",
        "            temperature=config.temperature,\n",
        "            google_api_key=config.api_key,\n",
        "        )\n",
        "        self.schema = self._create_extraction_schema()\n",
        "        self.extraction_chain = self.llm.with_structured_output(self.schema)\n",
        "\n",
        "    def _create_extraction_schema(self) -> Dict[str, Any]:\n",
        "        \"\"\"Define the schema for metadata extraction.\"\"\"\n",
        "        return {\n",
        "            \"name\": \"extract_metadata\",\n",
        "            \"description\": \"Extract metadata from text\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"title\": {\"type\": \"string\"},\n",
        "                    \"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                    \"summary\": {\"type\": \"string\"},\n",
        "                },\n",
        "                \"required\": [\"title\", \"keywords\", \"summary\"],\n",
        "            },\n",
        "        }\n",
        "\n",
        "    def extract_metadata_batch(self, documents: List[Document]) -> List[Document]:\n",
        "        \"\"\"Extract metadata for a batch of documents with rate limiting.\"\"\"\n",
        "        docs_with_metadata = []\n",
        "\n",
        "        for i, doc in enumerate(documents):\n",
        "            try:\n",
        "                logger.info(f\"Processing document {i+1}/{len(documents)}\")\n",
        "                extracted_data = self.extraction_chain.invoke(doc.page_content)\n",
        "\n",
        "                if extracted_data:\n",
        "                    keywords = extracted_data.get(\"keywords\", [])\n",
        "                    if isinstance(keywords, list):\n",
        "                        keywords = \", \".join(keywords)\n",
        "\n",
        "                    doc.metadata.update({\n",
        "                        \"title\": extracted_data.get(\"title\", \"Unknown\"),\n",
        "                        \"keywords\": keywords,\n",
        "                        \"summary\": extracted_data.get(\"summary\", \"\"),\n",
        "                        \"processed_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error extracting metadata for document {i+1}: {e}\")\n",
        "                doc.metadata.update({\n",
        "                    \"title\": \"Unknown\",\n",
        "                    \"keywords\": \"\",\n",
        "                    \"summary\": \"\",\n",
        "                    \"error\": str(e),\n",
        "                    \"processed_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                })\n",
        "\n",
        "            docs_with_metadata.append(doc)\n",
        "\n",
        "            # Rate limiting\n",
        "            if i < len(documents) - 1:  # Don't sleep after the last document\n",
        "                time.sleep(self.config.metadata_extraction_delay)\n",
        "\n",
        "        return docs_with_metadata\n",
        "\n",
        "\n",
        "class VectorStore:\n",
        "    \"\"\"Manages vector storage and retrieval operations.\"\"\"\n",
        "\n",
        "    def __init__(self, config: RAGConfig):\n",
        "        self.config = config\n",
        "        self.embeddings = GoogleGenerativeAIEmbeddings(\n",
        "            google_api_key=config.api_key,\n",
        "            model=config.embedding_model\n",
        "        )\n",
        "        self.store = None\n",
        "\n",
        "    def create_or_load_store(self, documents: List[Document]) -> None:\n",
        "        \"\"\"Create new vector store or load existing one.\"\"\"\n",
        "        try:\n",
        "            if Path(self.config.persist_directory).exists():\n",
        "                logger.info(\"Loading existing vector store...\")\n",
        "                self.store = Chroma(\n",
        "                    persist_directory=self.config.persist_directory,\n",
        "                    embedding_function=self.embeddings\n",
        "                )\n",
        "            else:\n",
        "                logger.info(\"Creating new vector store...\")\n",
        "                self.store = Chroma.from_documents(\n",
        "                    documents,\n",
        "                    self.embeddings,\n",
        "                    persist_directory=self.config.persist_directory\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error with vector store: {e}\")\n",
        "            raise\n",
        "\n",
        "    def search_similar(self, query: str, k: Optional[int] = None) -> List[Document]:\n",
        "        \"\"\"Search for similar documents with adaptive filtering.\"\"\"\n",
        "        if not self.store:\n",
        "            raise ValueError(\"Vector store not initialized\")\n",
        "\n",
        "        # Get more documents initially for filtering\n",
        "        search_k = (k or self.config.retrieval_k) * 2\n",
        "\n",
        "        retriever = self.store.as_retriever(\n",
        "            search_type=\"similarity_score_threshold\",\n",
        "            search_kwargs={\n",
        "                \"k\": search_k,\n",
        "                \"score_threshold\": self.config.score_threshold,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        initial_results = retriever.invoke(query)\n",
        "\n",
        "        if not initial_results:\n",
        "            return []\n",
        "\n",
        "        # If adaptive thresholding is enabled, apply additional filtering\n",
        "        if self.config.adaptive_threshold:\n",
        "            filtered_results = self._apply_adaptive_filtering(query, initial_results)\n",
        "            return filtered_results[:(k or self.config.retrieval_k)]\n",
        "\n",
        "        return initial_results[:(k or self.config.retrieval_k)]\n",
        "\n",
        "    def _apply_adaptive_filtering(self, query: str, documents: List[Document]) -> List[Document]:\n",
        "        \"\"\"Apply adaptive filtering to remove irrelevant documents.\"\"\"\n",
        "        if not documents:\n",
        "            return []\n",
        "\n",
        "        # Get similarity scores (if available from metadata)\n",
        "        # Note: Chroma doesn't directly expose scores, so we'll use content-based filtering\n",
        "\n",
        "        query_words = set(query.lower().split())\n",
        "        filtered_docs = []\n",
        "\n",
        "        for doc in documents:\n",
        "            doc_words = set(doc.page_content.lower().split())\n",
        "\n",
        "            # Calculate word overlap ratio\n",
        "            overlap = len(query_words.intersection(doc_words))\n",
        "            overlap_ratio = overlap / len(query_words) if query_words else 0\n",
        "\n",
        "            # Keep documents with reasonable word overlap or keyword matches\n",
        "            if (overlap_ratio > 0.1 or  # At least 10% word overlap\n",
        "                self._has_keyword_match(query, doc) or  # Keyword match in metadata\n",
        "                self._has_semantic_relevance(query, doc)):  # Basic semantic check\n",
        "                filtered_docs.append(doc)\n",
        "\n",
        "        return filtered_docs\n",
        "\n",
        "    def _has_keyword_match(self, query: str, document: Document) -> bool:\n",
        "        \"\"\"Check if query matches document keywords.\"\"\"\n",
        "        keywords = document.metadata.get(\"keywords\", \"\").lower()\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if not keywords:\n",
        "            return False\n",
        "\n",
        "        # Check if any query words match keywords\n",
        "        query_words = query_lower.split()\n",
        "        keyword_words = keywords.split(\", \")\n",
        "\n",
        "        return any(qword in keywords for qword in query_words)\n",
        "\n",
        "    def _has_semantic_relevance(self, query: str, document: Document) -> bool:\n",
        "        \"\"\"Basic semantic relevance check.\"\"\"\n",
        "        query_lower = query.lower()\n",
        "        content_lower = document.page_content.lower()\n",
        "\n",
        "        # Look for semantic clusters of related words\n",
        "        education_terms = [\"university\", \"college\", \"student\", \"academic\", \"education\", \"course\", \"degree\"]\n",
        "        legal_terms = [\"conviction\", \"criminal\", \"legal\", \"court\", \"law\", \"offense\"]\n",
        "        policy_terms = [\"policy\", \"procedure\", \"rule\", \"regulation\", \"guideline\"]\n",
        "\n",
        "        query_in_education = any(term in query_lower for term in education_terms)\n",
        "        query_in_legal = any(term in query_lower for term in legal_terms)\n",
        "        query_in_policy = any(term in query_lower for term in policy_terms)\n",
        "\n",
        "        content_has_education = any(term in content_lower for term in education_terms)\n",
        "        content_has_legal = any(term in content_lower for term in legal_terms)\n",
        "        content_has_policy = any(term in content_lower for term in policy_terms)\n",
        "\n",
        "        # Return True if query and content share semantic domain\n",
        "        return ((query_in_education and content_has_education) or\n",
        "                (query_in_legal and content_has_legal) or\n",
        "                (query_in_policy and content_has_policy))\n",
        "\n",
        "\n",
        "class RAGSystem:\n",
        "    \"\"\"Main RAG system orchestrating all components.\"\"\"\n",
        "\n",
        "    def __init__(self, config: RAGConfig):\n",
        "        self.config = config\n",
        "        self.doc_processor = DocumentProcessor(config)\n",
        "        self.metadata_extractor = MetadataExtractor(config)\n",
        "        self.vector_store = VectorStore(config)\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=config.chunk_size,\n",
        "            chunk_overlap=config.chunk_overlap\n",
        "        )\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            google_api_key=config.api_key,\n",
        "            temperature=config.temperature,\n",
        "            model=config.model_name\n",
        "        )\n",
        "        self.qa_template = self._create_qa_template()\n",
        "\n",
        "    def _create_qa_template(self) -> PromptTemplate:\n",
        "        \"\"\"Create the question-answering prompt template.\"\"\"\n",
        "        template = \"\"\"\n",
        "        Use the following pieces of context to answer the question at the end.\n",
        "        Answer based on the provided context. If the context contains relevant information, provide a helpful answer.\n",
        "        If the context doesn't contain enough relevant information to answer the question properly,\n",
        "        indicate that you cannot provide a complete answer based on the available information.\n",
        "        Do not make up answers or provide information not present in the context.\n",
        "\n",
        "        Context:\n",
        "        {context}\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        return PromptTemplate.from_template(template)\n",
        "\n",
        "    def initialize_system(self, force_reprocess: bool = False) -> None:\n",
        "        \"\"\"Initialize the RAG system by processing documents and creating vector store.\"\"\"\n",
        "        try:\n",
        "            # Load and clean documents\n",
        "            documents = self.doc_processor.load_and_clean_documents()\n",
        "\n",
        "            # Check if we need to reprocess\n",
        "            if force_reprocess or not Path(self.config.persist_directory).exists():\n",
        "                # Extract metadata\n",
        "                logger.info(\"Extracting metadata...\")\n",
        "                docs_with_metadata = self.metadata_extractor.extract_metadata_batch(documents)\n",
        "\n",
        "                # Split documents\n",
        "                logger.info(\"Splitting documents...\")\n",
        "                split_docs = self.text_splitter.split_documents(docs_with_metadata)\n",
        "\n",
        "                # Create vector store\n",
        "                logger.info(\"Creating vector store...\")\n",
        "                self.vector_store.create_or_load_store(split_docs)\n",
        "            else:\n",
        "                # Load existing vector store\n",
        "                self.vector_store.create_or_load_store([])\n",
        "\n",
        "            logger.info(\"RAG system initialized successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize RAG system: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _is_insufficient_answer(self, answer: str) -> bool:\n",
        "        \"\"\"Check if the answer indicates insufficient information.\"\"\"\n",
        "        insufficient_indicators = [\n",
        "            \"don't know\",\n",
        "            \"do not know\",\n",
        "            \"cannot answer\",\n",
        "            \"can't answer\",\n",
        "            \"cannot provide\",\n",
        "            \"can't provide\",\n",
        "            \"no information\",\n",
        "            \"not enough information\",\n",
        "            \"insufficient information\",\n",
        "            \"unable to answer\",\n",
        "            \"not available\",\n",
        "            \"not found in\",\n",
        "            \"not mentioned\",\n",
        "            \"not provided\",\n",
        "            \"cannot determine\",\n",
        "            \"can't determine\",\n",
        "            \"does not contain\",\n",
        "            \"doesn't contain\",\n",
        "            \"no relevant information\",\n",
        "            \"not relevant\",\n",
        "            \"cannot find\",\n",
        "            \"can't find\",\n",
        "            \"not specified\",\n",
        "            \"not clear from\",\n",
        "            \"unable to determine\"\n",
        "        ]\n",
        "\n",
        "        answer_lower = answer.lower().strip()\n",
        "\n",
        "        # Check if answer is very short (likely insufficient)\n",
        "        if len(answer.split()) < 5:\n",
        "            return True\n",
        "\n",
        "        # Check for insufficient indicators\n",
        "        for indicator in insufficient_indicators:\n",
        "            if indicator in answer_lower:\n",
        "                return True\n",
        "\n",
        "        # Check if answer starts with uncertainty phrases\n",
        "        uncertainty_starts = [\n",
        "            \"i cannot\",\n",
        "            \"i can't\",\n",
        "            \"i don't\",\n",
        "            \"i do not\",\n",
        "            \"there is no\",\n",
        "            \"there isn't\",\n",
        "            \"the context does not\",\n",
        "            \"the context doesn't\"\n",
        "        ]\n",
        "\n",
        "        for start in uncertainty_starts:\n",
        "            if answer_lower.startswith(start):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def query_documents(self, query: str, return_sources: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"Query the document collection and return structured results.\"\"\"\n",
        "        try:\n",
        "            # Retrieve similar documents\n",
        "            retrieved_docs = self.vector_store.search_similar(query)\n",
        "\n",
        "            # Check if we have enough relevant documents\n",
        "            if not retrieved_docs or len(retrieved_docs) < self.config.min_relevant_docs:\n",
        "                return {\n",
        "                    \"answer\": \"I don't have enough relevant information to answer this question based on the available documents.\",\n",
        "                    \"sources\": [],\n",
        "                    \"confidence\": \"low\",\n",
        "                    \"retrieved_docs_count\": len(retrieved_docs) if retrieved_docs else 0\n",
        "                }\n",
        "\n",
        "            # Create RAG chain\n",
        "            retrieve = {\n",
        "                \"context\": lambda x: \"\\n\\n\".join([doc.page_content for doc in retrieved_docs]),\n",
        "                \"question\": RunnablePassthrough()\n",
        "            }\n",
        "\n",
        "            rag_chain = (\n",
        "                retrieve\n",
        "                | self.qa_template\n",
        "                | self.llm\n",
        "                | StrOutputParser()\n",
        "            )\n",
        "\n",
        "            # Get answer\n",
        "            answer = rag_chain.invoke(query)\n",
        "\n",
        "            # Check if answer indicates insufficient information\n",
        "            is_insufficient = self._is_insufficient_answer(answer)\n",
        "\n",
        "            result = {\n",
        "                \"answer\": answer,\n",
        "                \"confidence\": \"low\" if is_insufficient else (\"high\" if len(retrieved_docs) >= 2 else \"medium\"),\n",
        "                \"retrieved_docs_count\": len(retrieved_docs)\n",
        "            }\n",
        "\n",
        "            # Only include sources if we have a meaningful answer and sources are requested\n",
        "            if return_sources and not is_insufficient:\n",
        "                result[\"sources\"] = [\n",
        "                    {\n",
        "                        \"title\": doc.metadata.get(\"title\", \"Unknown\"),\n",
        "                        \"keywords\": doc.metadata.get(\"keywords\", \"\"),\n",
        "                        \"page\": doc.metadata.get(\"page\", \"Unknown\")\n",
        "                    }\n",
        "                    for doc in retrieved_docs\n",
        "                ]\n",
        "            else:\n",
        "                result[\"sources\"] = []\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error querying documents: {e}\")\n",
        "            return {\n",
        "                \"answer\": f\"An error occurred while processing your query: {str(e)}\",\n",
        "                \"sources\": [],\n",
        "                \"confidence\": \"error\",\n",
        "                \"retrieved_docs_count\": 0\n",
        "            }\n",
        "\n",
        "    def batch_query(self, queries: List[str]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Process multiple queries and return results.\"\"\"\n",
        "        results = []\n",
        "        for query in queries:\n",
        "            logger.info(f\"Processing query: {query}\")\n",
        "            result = self.query_documents(query, return_sources=True)\n",
        "            results.append({\n",
        "                \"query\": query,\n",
        "                **result\n",
        "            })\n",
        "        return results"
      ],
      "metadata": {
        "id": "3f6PVQWAwTqY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Demonstrate the RAG system.\"\"\"\n",
        "# Configuration\n",
        "try:\n",
        "    # Try to import keys, fallback to environment variables\n",
        "    try:\n",
        "        import keys\n",
        "        config = RAGConfig(\n",
        "            file_path=keys.FILE_NAME,\n",
        "            api_key=keys.LLM_API_KEY\n",
        "        )\n",
        "    except ImportError:\n",
        "        config = RAGConfig(\n",
        "            file_path=os.getenv(\"FILE_NAME\", \"document.pdf\"),\n",
        "            api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        "        )\n",
        "\n",
        "    if not config.api_key:\n",
        "        raise ValueError(\"Google API key not found. Set GOOGLE_API_KEY environment variable or create keys.py\")\n",
        "\n",
        "    # Initialize RAG system\n",
        "    rag = RAGSystem(config)\n",
        "    rag.initialize_system()\n",
        "\n",
        "    # Example queries\n",
        "    test_queries = [\n",
        "        \"What do I need to be eligible?\",\n",
        "        \"How can I show language proficiency?\",\n",
        "        \"What are the ingredients of Carbonara?\",\n",
        "        \"What is the additional contribution of a person with ISEE of 30000?\"\n",
        "    ]\n",
        "\n",
        "    # Process queries\n",
        "    results = rag.batch_query(test_queries)\n",
        "\n",
        "    # Display results\n",
        "    for result in results:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Question: {result['query']}\")\n",
        "        print(f\"Confidence: {result['confidence']}\")\n",
        "        print(f\"Answer: {result['answer']}\")\n",
        "        if result.get('sources'):\n",
        "            print(\"\\nSources:\")\n",
        "            for source in result['sources']:\n",
        "                print(f\"  - {source['title']} (Page: {source['page']})\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Application error: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1mriB11x3XU",
        "outputId": "cb1aae7e-2e7c-4bd9-f057-d80d02e788e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Question: What do I need to be eligible?\n",
            "Confidence: high\n",
            "Answer: Based on the provided context, to be eligible, you need to meet the following requirements:\n",
            "\n",
            "*   **General Requirements for Eligibility** (ART. 5.1)\n",
            "*   **Language Requirements** (ART. 5.3)\n",
            "*   **Other Requirements** (ART. 5.4)\n",
            "\n",
            "Sources:\n",
            "  - Student Mobility Regulations (Page: 1)\n",
            "  - Student Mobility Regulations (Page: 1)\n",
            "  - Academic Score and Ranking Criteria for Master’s in Civil Engineering (Page: 13)\n",
            "\n",
            "============================================================\n",
            "Question: How can I show language proficiency?\n",
            "Confidence: high\n",
            "Answer: You can show language proficiency through a language proficiency test. These tests are multistage and include multiple-choice questions, cloze questions, and drag-and-drop activities within a text. The tests primarily focus on grammar and text comprehension, and do not include speaking or listening components. The test starts at the A2 level and progresses.\n",
            "\n",
            "Sources:\n",
            "  - Language Proficiency Requirements and Test Exemptions (Page: 8)\n",
            "  - Organization of Language Tests at the CLA (Page: 18)\n",
            "  - Preliminary Learning Project Scoring Criteria (Page: 24)\n",
            "\n",
            "============================================================\n",
            "Question: What are the ingredients of Carbonara?\n",
            "Confidence: low\n",
            "Answer: I cannot provide an answer to your question based on the provided context. The context discusses personal data processing, procedures, and language proficiency levels, but it does not contain any information about the ingredients of Carbonara.\n",
            "\n",
            "============================================================\n",
            "Question: What is the additional contribution of a person with ISEE of 30000?\n",
            "Confidence: high\n",
            "Answer: Based on the provided context, a person with an ISEE of 30,000 € would have an additional monthly contribution of **400,00 €**. This applies to both tax residents in Italy and participants with tax residence abroad.\n",
            "\n",
            "Sources:\n",
            "  - Additional Monthly Contribution based on ISEE (Page: 5)\n",
            "  - Additional Monthly Contribution based on ISEE (Page: 5)\n",
            "  - Additional Monthly Contribution based on ISEE (Page: 5)\n"
          ]
        }
      ]
    }
  ]
}